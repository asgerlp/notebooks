{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd701ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-us-east-1-293058073847\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "print(\"Using bucket \" + bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98828c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the California housing dataset\n",
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f299c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2143</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.288235</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>860.0</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>33.81</td>\n",
       "      <td>-118.12</td>\n",
       "      <td>2.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3468</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.364322</td>\n",
       "      <td>1.087940</td>\n",
       "      <td>957.0</td>\n",
       "      <td>2.404523</td>\n",
       "      <td>37.16</td>\n",
       "      <td>-121.98</td>\n",
       "      <td>2.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9191</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.110063</td>\n",
       "      <td>1.059748</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2.235849</td>\n",
       "      <td>38.45</td>\n",
       "      <td>-122.69</td>\n",
       "      <td>1.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3703</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>2.272549</td>\n",
       "      <td>34.16</td>\n",
       "      <td>-118.41</td>\n",
       "      <td>4.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.3684</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.795858</td>\n",
       "      <td>1.035503</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.088757</td>\n",
       "      <td>38.57</td>\n",
       "      <td>-121.33</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  4.2143      37.0  5.288235   0.973529       860.0  2.529412     33.81   \n",
       "1  5.3468      42.0  6.364322   1.087940       957.0  2.404523     37.16   \n",
       "2  3.9191      36.0  6.110063   1.059748       711.0  2.235849     38.45   \n",
       "3  6.3703      32.0  6.000000   0.990196      1159.0  2.272549     34.16   \n",
       "4  2.3684      17.0  4.795858   1.035503       706.0  2.088757     38.57   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -118.12   2.285  \n",
       "1    -121.98   2.799  \n",
       "2    -122.69   1.830  \n",
       "3    -118.41   4.658  \n",
       "4    -121.33   1.500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX[\"target\"] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "testX[\"target\"] = y_test\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c596f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv(\"california_housing_train.csv\")\n",
    "testX.to_csv(\"california_housing_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17f5805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"california_housing_train.csv\", bucket=bucket, key_prefix=\"sagemaker/sklearncontainer\"\n",
    ")\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path=\"california_housing_test.csv\", bucket=bucket, key_prefix=\"sagemaker/sklearncontainer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c96dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "datarobot\n",
    "https://asgerlp-public.s3.eu-central-1.amazonaws.com/datarobot_mlops-7.3.4-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9631ef72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import datarobot as dr\n",
    "from datarobot.mlops.mlops import MLOps\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    #initialize MLOps\n",
    "    os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"]=\"\"\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"]=\"\"\n",
    "    os.environ[\"AWS_SESSION_TOKEN\"]=\"\"\n",
    "\n",
    "    DEPLOYMENT_ID = ''\n",
    "    MODEL_ID = ''\n",
    "    SQS_QUEUE = ''\n",
    "\n",
    "    mlops = MLOps()\n",
    "    \n",
    "    try:\n",
    "        mlops.set_deployment_id(DEPLOYMENT_ID)\n",
    "        mlops.set_model_id(MODEL_ID)\n",
    "        mlops.set_sqs_spooler(SQS_QUEUE)\n",
    "    except:\n",
    "        print(\"Already set\")\n",
    "    \n",
    "    mlops.init()\n",
    "\n",
    "    # Pass values to the model\n",
    "    start_time = time.time()\n",
    "    prediction = model.predict(input_data)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    mlops.report_deployment_stats(1, end_time - start_time)\n",
    "    \n",
    "    features_df = pd.DataFrame.from_dict(input_data)\n",
    "    \n",
    "    mlops.report_predictions_data(features_df=features_df, predictions=prediction.tolist())\n",
    "\n",
    "    \n",
    "    return np.array([prediction])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"extracting arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"california_housing_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"california_housing_test.csv\")\n",
    "    parser.add_argument(\n",
    "        \"--features\", type=str\n",
    "    )  # in this script we ask user to explicitly name features\n",
    "    parser.add_argument(\n",
    "        \"--target\", type=str\n",
    "    )  # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"reading data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"building training and testing datasets\")\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    # train\n",
    "    print(\"training model\")\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators, min_samples_leaf=args.min_samples_leaf, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print abs error\n",
    "    print(\"validating model\")\n",
    "    abs_err = np.abs(model.predict(X_test) - y_test)\n",
    "\n",
    "    # print couple perf metrics\n",
    "    for q in [10, 50, 90]:\n",
    "        print(\"AE-at-\" + str(q) + \"th-percentile: \" + str(np.percentile(a=abs_err, q=q)))\n",
    "\n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(\"model persisted at \" + path)\n",
    "    print(args.min_samples_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15500e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Estimator from the SageMaker Python SDK\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "#    instance_type=\"local\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"rf-scikit\",\n",
    "    metric_definitions=[{\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"features\": \"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\n",
    "        \"target\": \"target\",\n",
    "    },\n",
    "    source_dir = '.',\n",
    "    env = {\n",
    "    'SAGEMAKER_REQUIREMENTS': 'requirements.txt', # path relative to `source_dir` below.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83a9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f171474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-11-21 23:03:16 Starting - Launching requested ML instances............\n",
      "2021-11-21 23:04:23 Starting - Preparing the instances for training...............\n",
      "2021-11-21 23:05:41 Downloading - Downloading input data...\n",
      "2021-11-21 23:06:03 Training - Downloading the training image...........\n",
      "2021-11-21 23:07:03 Uploading - Uploading generated training model.\n",
      "2021-11-21 23:07:12 Completed - Training job completed\n",
      "Model artifact persisted at s3://sagemaker-us-east-1-293058073847/rf-scikit-2021-11-21-23-03-13-559/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8e2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model = SKLearnModel(\n",
    "    model_data=artifact,\n",
    "    role=get_execution_role(),\n",
    "    entry_point=\"script.py\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    source_dir = '.',\n",
    "    env = {\n",
    "    'SAGEMAKER_REQUIREMENTS': 'requirements.txt', # path relative to `source_dir` below.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd6c568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(instance_type=\"ml.c5.large\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8adfae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49810276 0.7551042  4.79558254 ... 1.24873284 3.02558118 4.02814099]]\n"
     ]
    }
   ],
   "source": [
    "# the SKLearnPredictor does the serialization from pandas for us\n",
    "print(predictor.predict(testX[data.feature_names]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3.delete_endpoint(EndpointName=predictor.endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.predict(testX[data.feature_names]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50658f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
